{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo_weights.h5'):\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
    "    '''create the training model, for Tiny YOLOv3'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
    "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main\n",
    "#### Load path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotation_path = '2007_train.txt'\n",
    "log_dir = 'logs/000/'\n",
    "classes_path = 'model_data/voc_classes.txt'\n",
    "anchors_path = 'model_data/yolo_anchors.txt'\n",
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names)\n",
    "anchors = get_anchors(anchors_path)\n",
    "\n",
    "input_shape = (416,416) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create YOLOv3 model with 9 anchors and 20 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/yolo3/lib/python3.6/site-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 75) vs (255, 1024, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "/home/paperspace/anaconda3/envs/yolo3/lib/python3.6/site-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((75,) vs (255,)).\n",
      "  weight_values[i].shape))\n",
      "/home/paperspace/anaconda3/envs/yolo3/lib/python3.6/site-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 75) vs (255, 512, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "/home/paperspace/anaconda3/envs/yolo3/lib/python3.6/site-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((75,) vs (255,)).\n",
      "  weight_values[i].shape))\n",
      "/home/paperspace/anaconda3/envs/yolo3/lib/python3.6/site-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 75) vs (255, 256, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "/home/paperspace/anaconda3/envs/yolo3/lib/python3.6/site-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((75,) vs (255,)).\n",
      "  weight_values[i].shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weights model_data/yolo_weights.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n"
     ]
    }
   ],
   "source": [
    "is_tiny_version = len(anchors)==6 # default setting\n",
    "if is_tiny_version:\n",
    "    model = create_tiny_model(input_shape, anchors, num_classes,\n",
    "        freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n",
    "else:\n",
    "    model = create_model(input_shape, anchors, num_classes,\n",
    "        freeze_body=2, weights_path='model_data/yolo_weights.h5') \n",
    "\n",
    "logging = TensorBoard(log_dir=log_dir)\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_split = 0.1\n",
    "with open(annotation_path) as f:\n",
    "    lines = f.readlines()\n",
    "np.random.seed(10101)\n",
    "np.random.shuffle(lines)\n",
    "np.random.seed(None)\n",
    "num_val = int(len(lines)*val_split)\n",
    "num_train = len(lines) - num_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2251 samples, val on 250 samples, with batch size 32.\n",
      "Epoch 1/40\n",
      "70/70 [==============================] - 214s 3s/step - loss: 1094.3018 - val_loss: 147.3524\n",
      "Epoch 2/40\n",
      "70/70 [==============================] - 174s 2s/step - loss: 113.1878 - val_loss: 87.3452\n",
      "Epoch 3/40\n",
      "70/70 [==============================] - 178s 3s/step - loss: 74.8848 - val_loss: 62.6081\n",
      "Epoch 4/40\n",
      "70/70 [==============================] - 151s 2s/step - loss: 58.0679 - val_loss: 51.6668\n",
      "Epoch 5/40\n",
      "70/70 [==============================] - 176s 3s/step - loss: 49.1476 - val_loss: 46.1585\n",
      "Epoch 6/40\n",
      "70/70 [==============================] - 179s 3s/step - loss: 43.7536 - val_loss: 40.5489\n",
      "Epoch 7/40\n",
      "70/70 [==============================] - 176s 3s/step - loss: 39.6087 - val_loss: 39.3280\n",
      "Epoch 8/40\n",
      "70/70 [==============================] - 177s 3s/step - loss: 36.9756 - val_loss: 35.7303\n",
      "Epoch 9/40\n",
      "70/70 [==============================] - 176s 3s/step - loss: 35.0359 - val_loss: 34.0788\n",
      "Epoch 10/40\n",
      "70/70 [==============================] - 176s 3s/step - loss: 33.2806 - val_loss: 31.3157\n",
      "Epoch 11/40\n",
      "70/70 [==============================] - 177s 3s/step - loss: 31.8004 - val_loss: 32.0234\n",
      "Epoch 12/40\n",
      "70/70 [==============================] - 177s 3s/step - loss: 30.8393 - val_loss: 30.7936\n",
      "Epoch 13/40\n",
      "70/70 [==============================] - 177s 3s/step - loss: 30.0735 - val_loss: 29.1896\n",
      "Epoch 14/40\n",
      "70/70 [==============================] - 179s 3s/step - loss: 29.1685 - val_loss: 28.7901\n",
      "Epoch 15/40\n",
      "70/70 [==============================] - 176s 3s/step - loss: 28.0717 - val_loss: 26.2862\n",
      "Epoch 16/40\n",
      "70/70 [==============================] - 164s 2s/step - loss: 28.0032 - val_loss: 28.3320\n",
      "Epoch 17/40\n",
      "70/70 [==============================] - 167s 2s/step - loss: 27.5228 - val_loss: 27.8561\n",
      "Epoch 18/40\n",
      "70/70 [==============================] - 164s 2s/step - loss: 26.9601 - val_loss: 27.3286\n",
      "Epoch 19/40\n",
      "70/70 [==============================] - 166s 2s/step - loss: 26.5993 - val_loss: 27.0436\n",
      "Epoch 20/40\n",
      "70/70 [==============================] - 164s 2s/step - loss: 26.2540 - val_loss: 26.6072\n",
      "Epoch 21/40\n",
      "70/70 [==============================] - 166s 2s/step - loss: 25.8259 - val_loss: 26.2892\n",
      "Epoch 22/40\n",
      "70/70 [==============================] - 167s 2s/step - loss: 25.6098 - val_loss: 25.2840\n",
      "Epoch 23/40\n",
      "70/70 [==============================] - 166s 2s/step - loss: 25.1324 - val_loss: 26.1071\n",
      "Epoch 24/40\n",
      "70/70 [==============================] - 167s 2s/step - loss: 25.0633 - val_loss: 25.1315\n",
      "Epoch 25/40\n",
      "70/70 [==============================] - 167s 2s/step - loss: 24.6488 - val_loss: 24.7960\n",
      "Epoch 26/40\n",
      "70/70 [==============================] - 169s 2s/step - loss: 25.0692 - val_loss: 25.5822\n",
      "Epoch 27/40\n",
      "70/70 [==============================] - 162s 2s/step - loss: 24.3273 - val_loss: 24.0217\n",
      "Epoch 28/40\n",
      "70/70 [==============================] - 166s 2s/step - loss: 24.2488 - val_loss: 26.0549\n",
      "Epoch 29/40\n",
      "70/70 [==============================] - 165s 2s/step - loss: 24.2678 - val_loss: 24.3965\n",
      "Epoch 30/40\n",
      "70/70 [==============================] - 165s 2s/step - loss: 23.6063 - val_loss: 23.6868\n",
      "Epoch 31/40\n",
      "70/70 [==============================] - 165s 2s/step - loss: 23.9440 - val_loss: 24.3920\n",
      "Epoch 32/40\n",
      "70/70 [==============================] - 164s 2s/step - loss: 23.9734 - val_loss: 24.8479\n",
      "Epoch 33/40\n",
      "70/70 [==============================] - 164s 2s/step - loss: 23.5888 - val_loss: 22.3001\n",
      "Epoch 34/40\n",
      "70/70 [==============================] - 163s 2s/step - loss: 23.3500 - val_loss: 24.6659\n",
      "Epoch 35/40\n",
      "70/70 [==============================] - 168s 2s/step - loss: 23.2870 - val_loss: 24.1754\n",
      "Epoch 36/40\n",
      "70/70 [==============================] - 167s 2s/step - loss: 23.6272 - val_loss: 23.9162\n",
      "Epoch 37/40\n",
      "70/70 [==============================] - 165s 2s/step - loss: 23.2951 - val_loss: 23.7893\n",
      "Epoch 38/40\n",
      "70/70 [==============================] - 163s 2s/step - loss: 22.8459 - val_loss: 23.7690\n",
      "Epoch 39/40\n",
      "70/70 [==============================] - 168s 2s/step - loss: 23.2178 - val_loss: 24.0545\n",
      "Epoch 40/40\n",
      "70/70 [==============================] - 168s 2s/step - loss: 22.8056 - val_loss: 23.8815\n",
      "Unfreeze all of the layers.\n",
      "Train on 2251 samples, val on 250 samples, with batch size 8.\n",
      "Epoch 41/80\n",
      "281/281 [==============================] - 411s 1s/step - loss: 23.1248 - val_loss: 23.2498\n",
      "Epoch 42/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 22.3313 - val_loss: 23.1166\n",
      "Epoch 43/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 21.9222 - val_loss: 23.2730\n",
      "Epoch 44/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 21.9304 - val_loss: 23.6104\n",
      "Epoch 45/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 21.6911 - val_loss: 23.3097\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 46/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 20.6528 - val_loss: 22.4114\n",
      "Epoch 47/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 19.9284 - val_loss: 21.8964\n",
      "Epoch 48/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 19.6222 - val_loss: 22.1847\n",
      "Epoch 49/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 19.2579 - val_loss: 21.6575\n",
      "Epoch 50/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 19.2458 - val_loss: 21.2527\n",
      "Epoch 51/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 19.0576 - val_loss: 21.7711\n",
      "Epoch 52/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 19.0779 - val_loss: 21.2251\n",
      "Epoch 53/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 18.6508 - val_loss: 21.4927\n",
      "Epoch 54/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 18.8718 - val_loss: 20.7148\n",
      "Epoch 55/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 18.5048 - val_loss: 22.3659\n",
      "Epoch 56/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 18.4960 - val_loss: 21.1155\n",
      "Epoch 57/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 18.4774 - val_loss: 20.5364\n",
      "Epoch 58/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 18.4872 - val_loss: 21.6130\n",
      "Epoch 59/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 18.3362 - val_loss: 20.9932\n",
      "Epoch 60/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 18.4301 - val_loss: 21.0656\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 61/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 18.0159 - val_loss: 22.2350\n",
      "Epoch 62/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 18.1283 - val_loss: 21.1383\n",
      "Epoch 63/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 18.1210 - val_loss: 21.3039\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 64/80\n",
      "281/281 [==============================] - 387s 1s/step - loss: 18.0884 - val_loss: 20.8111\n",
      "Epoch 65/80\n",
      "281/281 [==============================] - 390s 1s/step - loss: 17.9405 - val_loss: 21.5840\n",
      "Epoch 66/80\n",
      "281/281 [==============================] - 393s 1s/step - loss: 18.0263 - val_loss: 20.3221\n",
      "Epoch 67/80\n",
      "281/281 [==============================] - 393s 1s/step - loss: 18.1173 - val_loss: 22.0898\n",
      "Epoch 68/80\n",
      "281/281 [==============================] - 395s 1s/step - loss: 18.1446 - val_loss: 20.6797\n",
      "Epoch 69/80\n",
      "281/281 [==============================] - 392s 1s/step - loss: 18.0415 - val_loss: 22.0700\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 70/80\n",
      "281/281 [==============================] - 393s 1s/step - loss: 17.8999 - val_loss: 20.4374\n",
      "Epoch 71/80\n",
      "281/281 [==============================] - 393s 1s/step - loss: 17.9770 - val_loss: 21.9942\n",
      "Epoch 72/80\n",
      "281/281 [==============================] - 394s 1s/step - loss: 18.0032 - val_loss: 20.9489\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 73/80\n",
      "281/281 [==============================] - 395s 1s/step - loss: 18.0695 - val_loss: 21.8250\n",
      "Epoch 74/80\n",
      "281/281 [==============================] - 393s 1s/step - loss: 17.9535 - val_loss: 21.2736\n",
      "Epoch 75/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 393s 1s/step - loss: 17.9992 - val_loss: 20.9309\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 76/80\n",
      "281/281 [==============================] - 394s 1s/step - loss: 18.1950 - val_loss: 20.7839\n",
      "Epoch 00076: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train with frozen layers first, to get a stable loss.\n",
    "if True:\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "        # use custom yolo_loss Lambda layer.\n",
    "        'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "    batch_size = 32\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "    model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=40,\n",
    "            initial_epoch=0,\n",
    "            callbacks=[logging, checkpoint])\n",
    "    model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "# Unfreeze and continue training, to fine-tune.\n",
    "if True:\n",
    "    for i in range(len(model.layers)):\n",
    "        model.layers[i].trainable = True\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "    print('Unfreeze all of the layers.')\n",
    "\n",
    "    batch_size = 8 # note that more GPU memory is required after unfreezing the body\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "    model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "        steps_per_epoch=max(1, num_train//batch_size),\n",
    "        validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "        validation_steps=max(1, num_val//batch_size),\n",
    "        epochs=80,\n",
    "        initial_epoch=40,\n",
    "        callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "    model.save_weights(log_dir + 'trained_weights_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yolo3",
   "language": "python",
   "name": "yolo3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
